<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://gua927.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://gua927.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-07T15:09:38+00:00</updated><id>https://gua927.github.io/feed.xml</id><title type="html">Runze Tian</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html"></title><link href="https://gua927.github.io/blog/2025/2025-11-07-Note-AR2Diff/" rel="alternate" type="text/html" title=""/><published>2025-11-07T15:09:38+00:00</published><updated>2025-11-07T15:09:38+00:00</updated><id>https://gua927.github.io/blog/2025/2025-11-07-Note-AR2Diff</id><content type="html" xml:base="https://gua927.github.io/blog/2025/2025-11-07-Note-AR2Diff/"><![CDATA[<h1 id="融合序列精确性与并行效率连接自回归模型与分数基采样">融合序列精确性与并行效率：连接自回归模型与分数基采样</h1> <h2 id="introduction">Introduction</h2> <p>序列化精度与并行化效率的矛盾统一在生成模型领域，自回归模型（Autoregressive, AR）和分数基生成模型（Score-Based Generative Models, SGM，如扩散模型）各自占据优势。AR 模型依赖于最大似然估计（MLE）进行精确的密度建模 1，在数据效率和训练初期的稳定收敛上表现出色 3，是当前 AI 算力持续增长而高质量训练数据增长开始放缓时代下的理想选择 4。然而，AR 模型固有的<strong>祖先采样（Ancestral Sampling）</strong>机制，要求逐令牌（token-by-token）生成，导致推理速度受到序列长度 $L$ 的严格限制 5。相比之下，扩散模型等分数基方法虽然训练难度和资源消耗较大，但在推理阶段可以利用朗之万动力学（Langevin Dynamics）等技术进行大规模并行采样，实现显著加速 8。本文的核心探究目标在于实现一种范式合成：保留 AR 模型在 MLE 训练中所建立的高保真度密度估计器，同时采用 SGM 固有的、通过梯度引导的并行采样能力。 重点在于探索如何通过分数函数（Score Function），尤其是其针对离散数据的推广形式——Concrete Score，实现从 AR 似然到并行解码的“训练免费”（Training-Free）或“训练简单”（Training-Easy）转换 9。</p> <h2 id="current-genmodel">Current GenModel</h2> <p>自回归与扩散模型的关键权衡</p> <table> <tbody> <tr> <td>A. 自回归模型的精准似然与训练优势AR 模型的核心优势在于其对联合概率分布 $p(x)$ 的解析建模，即：$$p(x) = \prod_{i=1}^L p(x_i</td> <td>x_{&lt;i})$$这种基于链式法则的分解允许对数据分布进行精确的对数似然计算和 MLE 优化</td> </tr> </tbody> </table> <p>在训练初期（如单次迭代周期），AR 模型通常能取得显著优于扩散模型的性能（如损失值10.65 vs. 7.07） 3。这种训练的严谨性和稳定性使其成为在追求高保真度时最大限度利用现有数据的有效选择 4。B. 顺序推理的固有成本与并行化探索AR 模型在生成长度为 $L$ 的序列时，需要 $L$ 次顺序计算步骤。这种固有的顺序依赖性限制了模型在推理时的墙钟并行性（wall-clock parallelism）</p> <p>6。为了突破这一瓶颈，研究人员探索了各种并行解码方法，例如基于迭代细化的非自回归（Non-AR）方法，如 Mask-Predict 7、变分自回归模型（VAR） 10 或离散扩散模型 ，这些方法旨在通过并行块生成来实现显著的解码加速 11。这些并行路径最终都指向了一个共同的数学工具：分数函数。</p> <h2 id="score-function-and-concrete-score">Score Function and Concrete Score</h2> <p>并行生成的通用语言要将 AR 模型的密度估计能力转化为并行生成能力，必须引入分数函数。</p> <h3 id="a-连续分数函数与朗之万动力学分数函数">A. 连续分数函数与朗之万动力学分数函数</h3> <p>$s(x)$ 定义为对数概率密度函数的梯度：\(s(x) = \nabla_x \log p(x)\)这个梯度向量场指向数据流形上概率密度更高的区域 。SGM 的优势在于只需要建模和估计这个梯度，从而避开了计算概率密度函数 $p(x)$ 中可能无法解析的归一化常数（partition function） 12。实现并行性的关键是利用分数函数指导朗之万动力学（Langevin Dynamics）：\(x_{t+1} = x_t + \frac{\eta}{2} \nabla_x \log p(x_t) + \sqrt{\eta} \epsilon_t\)与顺序的 AR 采样不同，这个更新步骤可以在 $x$ 的所有维度上同时操作，从而实现了大规模的并行化 5。AR 模型通过 MLE 训练确定了完整的联合似然 $p(x)$ 2。由于 $\log p(x)$ 理论上是可导出的，因此其空间梯度 $\nabla_x \log p(x)$ 也理论上可得 15。</p> <h3 id="concrete-score">Concrete Score</h3> <p>离散数据的梯度泛化当 $x$ 是离散的（如文本令牌），传统的梯度 $\nabla_x \log p(x)$ 在数学上是未定义的 15。这构成了直接将 AR 似然转换为并行采样器的核心障碍 19。为了将分数基方法的优势扩展到离散领域，研究人员提出了 Concrete Score $c_p(x)$ 15。定义： Concrete Score 是连续领域 Stein Score 的推广 20。它不依赖于微分，而是基于概率随输入局部方向性变化的速率来定义 20。机制： Concrete Score 通过考虑在预定义的邻域结构下（例如在离散空间中使用曼哈顿距离代替欧几里得距离 3）两个相邻样本之间的相似性，在离散空间中构造出替代梯度信息 15。这种推广使得分数基生成模型得以应用于文本、图形和基因序列等结构化离散数据 3。</p> <h2 id="ar2diff-in-consistency-space">AR2Diff in consistency space</h2> <p>连续或潜在空间的转换在 AR 模型输出为连续值（如原始音频信号）或通过变分自编码器（VAE）等映射到连续潜在码的情况下，梯度是可计算或可近似的。</p> <h3 id="a训练免费的并行且灵活采样">A.训练免费的并行且灵活采样</h3> <p>(PnF)针对连续域，<strong>“并行且灵活采样”（Parallel and Flexible Sampling, PnF）技术实现了真正的“训练免费”</strong>转换 。平滑操作： PnF 针对 AR 模型输出的离散化（例如 8 位音频样本）问题，采用高斯卷积 $\phi_{\sigma}$ 对离散分布 $p(x)$ 进行平滑处理 $p_{\sigma}(x) = (\phi_{\sigma} * p)(x)$ 5。这有效地将离散的概率质量函数转换为连续、可微的概率密度函数 5。解析推导： 平滑后的分布 $p_{\sigma}(x)$ 的梯度 $\nabla_x \log p_{\sigma}(x)$ 可以通过解析形式计算，这个过程完全利用原始预训练的 AR 模型，无需任何额外的训练或梯度估计 9。并行性： PnF 利用朗之万动力学在序列维度上并行生成，将确定性的顺序计算替换为了随机的并行 MCMC 过程 。PnF 采样相对于祖先采样实现了显著的加速，墙钟时间对序列长度 $L$ 表现出对数线性依赖 5。</p> <h3 id="b-变分潜在空间vssm">B. 变分潜在空间（VSSM）</h3> <p>桥接的另一种方法是利用变分状态空间模型（VSSM） 或类似的 VAE 结构。VSSM 采用 VAE 结构，并通过 Gumbel 重参数化技巧 (Gumbel-Softmax) 在离散潜在空间 $z$ 中进行采样 。Gumbel-Softmax 提供了对离散采样过程进行可微分近似的能力 ，使得潜在序列 $z$ 的并行解码对梯度优化变得可行 。这展示了 AR 模型可以将其序列化和离散化转移到可并行优化的潜在空间，从而重用强大的 AR 训练模型 。</p> <h2 id="ar2diff-in-discrete-space">AR2Diff in discrete space</h2> <p>分类令牌的融合之路对于文本令牌等纯粹的、不可微的分类离散数据，PnF 所依赖的连续性假设不再成立 5。将 AR 似然转化为并行解码器需要引入训练步骤。</p> <h3 id="aconcrete-score-matching-csm">A.Concrete Score Matching (CSM)</h3> <p>离散域，通常采用 Concrete Score Matching (CSM) 方法来训练一个专用的分数模型 $\tilde{s}<em>\theta(\tilde{x})$ 20。这标志着从“训练免费”到<strong>“训练简单”或“训练微调”</strong>的路径转换 22。去噪 CSM (D-CSM)： CSM 的一个常用变体是 D-CSM 23，它训练分数模型 $\tilde{s}</em>\theta(\tilde{x})$ 通过去噪目标来匹配 Concrete Score 22。这个训练目标与<strong>离散扩散模型（DDM）</strong>的学习目标本质上是高度一致的：即学习逆转加性噪声（如随机掩码）的过程 24。AR 知识的迁移： Concrete Score 充当了将 AR 模型的精确似然知识转化为 DDM 并行去噪能力的学习目标 19。</p> <h3 id="b-与大规模语言模型的集成与迭代细化通过对齐推理过程">B. 与大规模语言模型的集成与迭代细化通过对齐推理过程</h3> <p>，可以将预训练的 AR-trained Transformer 主干网络与并行生成所需的去噪/扩散步骤相结合 26。例如，Diffusion-NAT 方法将离散扩散的去噪过程与预训练的非自回归解码器（如 BART）统一起来 26，使得模型能够利用预训练的知识进行迭代的掩码令牌（masked token）细化 26。这种方法在保持生成速度（比 AR Transformer 快 20 倍）的同时，利用了 AR 模型的预训练知识 26。迭代细化范式（例如 Mask-Predict 7）本身也高度依赖于隐式的“信心分数”（Confidence Score）来指导修正，这与基于 Concrete Score 的去噪过程在操作上具有趋同性——即通过识别低似然或噪声区域并同时改进它们来实现并行生成 7。</p> <h2 id="conclusion">Conclusion</h2> <p>融合 AR 精度与 SGM 并行性的新范式将 AR 模型与分数基采样方法相结合，为生成建模提供了一个强大的框架，旨在同时利用 MLE 训练的高保真度和 SGM 的并行采样效率 3。A. 范式融合的实现与挑战范式核心推理原则适用领域推理并行性训练要求自回归 (AR)顺序条件似然离散/连续无 (顺序)MLE (高保真度) 1AR-to-Score (PnF)基于平滑似然的梯度引导 MCMC连续/潜在编码 5高 (MCMC 步骤 $O(T)$)训练免费 (后验处理) 9掩码语言模型 (Mask-Predict)基于信心的迭代细化离散 (文本) 7中 (块并行)训练简单 (非 AR 目标) 7离散分数/扩散 (CSM)通过显式分数匹配进行去噪离散 (文本, 图形) 20高 (去噪步骤 $O(T)$)训练较重 (需要分数匹配) 3关键权衡：速度与质量： AR-to-Score 和 DDM 的总延迟取决于迭代 MCMC/去噪步骤的数量 ($T_{steps}$) 5。虽然它们在序列长度上是并行的，但样本质量高度依赖于 $T_{steps}$ 5。泛化挑战： 对于纯粹的分类离散数据，找到一种数学上严谨且真正的“训练免费”方法来推导其 Concrete Score 仍然是一个主要的开放挑战 15。目前的解决方案大多需要通过 CSM 引入新的训练目标 22。B. 未来研究展望未来的研究应专注于优化迭代效率，即大幅减少朗之万或去噪的迭代步骤数 $T_{steps}$，同时保持样本的高质量 5。此外，开发更高效、更通用的离散分数估计器，使其能够从现有的离散 AR 似然中低成本地提取，将是扩大“训练简单”方法适用范围的关键 20。通过架构集成，在同一模型中同时训练 AR 似然和 Concrete Score 匹配目标，从而在训练阶段就内建并行采样的能力，将进一步优化总体训练和推理预算 24。</p>]]></content><author><name></name></author></entry><entry><title type="html">Flow Matching and Continuous Normalizing Flows</title><link href="https://gua927.github.io/blog/2025/Note-FM/" rel="alternate" type="text/html" title="Flow Matching and Continuous Normalizing Flows"/><published>2025-11-05T12:00:00+00:00</published><updated>2025-11-05T12:00:00+00:00</updated><id>https://gua927.github.io/blog/2025/Note-FM</id><content type="html" xml:base="https://gua927.github.io/blog/2025/Note-FM/"><![CDATA[<h2 id="overview">Overview</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-5-Note-FM/figure1-480.webp 480w,/assets/img/posts/2025-11-5-Note-FM/figure1-800.webp 800w,/assets/img/posts/2025-11-5-Note-FM/figure1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-5-Note-FM/figure1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Flow-based Models</strong> are generative models based on <strong>Normalizing Flows (NFs)</strong>, which transform complex probability distributions into simple ones through a series of probability density function transformations, and generate new data samples through inverse transformations. <strong>Continuous Normalizing Flows (CNFs)</strong> extend <strong>Normalizing Flows</strong> by using ordinary differential equations (<strong>ODEs</strong>) to represent continuous transformation processes for modeling probability distributions.</p> <p><strong>Flow Matching (FM)</strong> is a method for training <strong>Continuous Normalizing Flows</strong> that trains the model by learning <strong>Vector Fields</strong> associated with probability paths, and uses <strong>ODE</strong> solvers to generate new samples.</p> <p>Diffusion models are a special case of <strong>Flow Matching</strong> applications. Using FM can improve their training stability. Furthermore, constructing probability paths using <strong><em>Optimal Transport</em></strong> techniques can further accelerate training speed and enhance model generalization ability.</p> <h2 id="normalizing-flows">Normalizing Flows</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-5-Note-FM/figure2-480.webp 480w,/assets/img/posts/2025-11-5-Note-FM/figure2-800.webp 800w,/assets/img/posts/2025-11-5-Note-FM/figure2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-5-Note-FM/figure2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Normalizing Flows (NFs)</strong> are invertible probability density transformation methods whose core idea is to progressively transform a simple distribution (typically a Gaussian distribution) into a complex target distribution through a series of invertible transformation functions. <strong>This process can be viewed as an iterative sequence of variable substitutions, where each substitution follows the change of variables principle for probability density functions</strong>. Through this approach, <strong>Normalizing Flows</strong> can precisely compute the probability density of the transformed distribution, thereby achieving an exact mapping from simple to complex distributions.</p> <p>Let $p_0(\mathbf{z_0})$ be the original simple distribution (e.g., standard Gaussian distribution). <strong><em>Normalizing Flows</em></strong> aim to transform it into the target distribution $p(x)$ through a series of invertible transformations $f_i$. These transformations define a mapping from $z_0$ to $x$, and each transformation $f_i$ has its inverse transformation $f_i^{-1}$. Thus, the transformation process can be represented as:</p> \[x=z_K=f_K\circ f_{K-1}\circ\cdots\circ f_1(z_0)\] <p>For the $i$-th step, we have:</p> \[\mathbf{z}_{i-1} \sim p_{i-1}(\mathbf{z}_{i-1})\\ \mathbf{z}_i = f_i(\mathbf{z}_{i-1}), \quad \text{thus } \mathbf{z}_{i-1} = f_i^{-1}(\mathbf{z}_i)\] <p>According to the change of variables formula for probability density functions, we obtain:</p> \[\begin{align*} p_i(\mathbf{z}_i) &amp;= p_{i-1}(f_i^{-1}(\mathbf{z}_i)) \left| \det \left( \frac{d f_i^{-1}}{d \mathbf{z}_i} \right) \right|\\ &amp;= p_{i-1}(\mathbf{z}_{i-1}) \left| \det \left( \frac{d f_i}{d \mathbf{z}_{i-1}} \right)^{-1} \right|\\ &amp;= p_{i-1}(\mathbf{z}_{i-1}) \left| \det \left( \frac{d f_i}{d \mathbf{z}_{i-1}} \right) \right|^{-1} \end{align*}\] <p>The log-likelihood is given by:</p> \[\log p_i(x)=\log p_{i-1}(z_{K-1})-\log\bigg|\det\frac{df_i}{dz_{i-1}}\bigg|\] <p>Thus we have</p> \[\log p(x)=\log \pi_0(z_0)-\sum\limits_{i=1}^{K}\log\bigg|\det\frac{df_i}{dz_{i-1}} \bigg|\] <p>When this series of transformation functions $f_i$ are invertible and the Jacobian matrices are tractable to compute, during model training, the optimization objective is the negative log-likelihood:</p> \[\mathcal L(\mathcal D)=-\frac{1}{\mathcal D}\sum_{x\in\mathcal D}\log p(x)\] <h2 id="expressive-power-of-flow-based-models">Expressive Power of Flow-Based Models</h2> <p>We consider whether we can transform a simple distribution $p(u)$ into any arbitrary probability distribution $p(x)$. Assume $x$ is a $D$-dimensional vector with $p(x)&gt;0$, and the probability distribution of $x_i$ depends only on the previous elements $x_{1:i-1}$. Then we can decompose $p_x(x)$ as a product of conditional probabilities</p> \[p_x(x)=\prod_{i=1}^{D}p_x(x_i|x_{1:i-1})\] <p>Assume the transformation $F$ maps $x$ to $z$, where the value of $z_i$ is determined by the cumulative distribution function (CDF) of $x_i$</p> \[z_i=F_i(x_i,x_{1:i-1})=\int_{-\infty}^{x_i}p_x(x_i'|x_{1:i-1})dx'_i=P(x'_i\le x_i|x_{1:i-1})\] <p>Clearly, $F_i$ is differentiable, and its partial derivative with respect to $x_i$ equals $p_x(x_i|x_{1:i-1})$. Since the partial derivative of $F_i$ with respect to $x_j~(j&gt;i)$ is 0, $J_F(x)$ is a lower triangular matrix, and thus its determinant equals the product of its diagonal elements, i.e.,</p> \[\det J_F(x)=\prod_{i=1}^{D}\frac{\partial F_i}{\partial x_i}=\prod_{i=1}^{D}p_x(x_i|x_{1:i-1})=p_x(x)&gt;0\] <p>Since $p_x(x)&gt;0$, the determinant is also greater than zero, thus the inverse of transformation $F$ must exist. Therefore, we have</p> \[p_z(z)=p_x(x)|\det J_F(x)|^{-1}=1\] <p>i.e., $z$ follows a uniform distribution $[0,1]^D$ in $D$-dimensional space.</p> <p>From the above discussion, we can see that we can transform any distribution into a uniform distribution, and also transform a uniform distribution into any distribution. Thus, through normalizing flows, we can achieve mutual transformation between any two distributions.</p> <h2 id="continuous-normalizing-flows">Continuous Normalizing Flows</h2> <p><strong>Continuous Normalizing Flows (CNFs)</strong> are an extension of <strong>Normalizing Flows</strong> that can better model complex probability distributions. In traditional <strong>Normalizing Flows</strong>, transformations are typically defined through a series of <strong>invertible discrete functions</strong>, whereas in <strong>CNFs</strong>, these transformations are <strong>continuous</strong>, enabling the model to adapt more smoothly to data distributions and enhancing the model’s expressive power.</p> <p>In the continuous setting, <strong><em>FM</em></strong> can be formalized as follows:</p> <ul> <li> <p><strong><em>Trajectory</em></strong></p> <p>A trajectory is a mapping from time to sample position. The input is $t$, and the output is $X_t$. The domain of $t$ is $[0,1]$, and the domain of $X_t$ is $\mathbb R^d$</p> \[X:[0,1]\to \mathbb R^d,\quad t\to X_t\] <p>At $t=0$, $X_0$ comes from a simple initial distribution $p_{init}$. At time $t=1$, we want $X_1$ to follow the true data distribution $p_{data}$.</p> </li> <li> <p><strong><em>Vector Field</em></strong></p> <p>A vector field is a mapping from position and time to instantaneous velocity. The inputs are <strong><em>location</em></strong> and <strong><em>time</em></strong>, and the output is <strong><em>velocity</em></strong>.</p> \[u:\mathbb R^d\times[0,1]\to \mathbb R^d,\quad (x,t)\to u_t(x)\] <p>At any position $x$ and any time $t$, the vector field provides the direction and speed of sample transformation.</p> </li> <li> <p><strong><em>ODE</em></strong></p> <p>The trajectory $X_t$ must satisfy the following initial value problem:</p> \[\frac{d}{dt}X_t=u_t(X_t),\quad X_0=x_0\] <p>Here, $x_0\sim p_{init}$ is a sample from the initial simple distribution.</p> <p>Solving an ordinary differential equation means finding a curve $X_t$ such that its tangent velocity at each time $t$ exactly equals the value of the vector field $u_t$ at its position (i.e., the derivative of $X_t$ equals $u_t$). That is, solving this differential equation yields the path starting from $x_0$.</p> </li> <li> <p><strong><em>Flow</em></strong></p> <p>A flow is a mapping of the evolution of the initial point $x_0$ at each time, denoted as</p> \[\psi_t(x_0)=X_t\] <p>with domain $\psi:\mathbb R^d\times[0,1]\to \mathbb R^d,\quad (x_0,t)\to X_t$</p> <ul> <li> <p>The flow tells us the position of the sample at time $t$ starting from $X_0=x_0,t=0$, i.e., what $X_t$ is.</p> </li> <li> <p>The flow is the solution satisfying the above <strong><em>ODE</em></strong>: \(\frac{d}{dt}\psi_t(x_0)=u_t(\psi_t(x_0)),~\psi_0(x_0)=x_0\)</p> </li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-5-Note-FM/figure3-480.webp 480w,/assets/img/posts/2025-11-5-Note-FM/figure3-800.webp 800w,/assets/img/posts/2025-11-5-Note-FM/figure3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-5-Note-FM/figure3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In practice, when using <strong><em>CNFs</em></strong>, we need to first estimate the vector field $u_t(x)$, which can be approximated by a neural network $u_t^{\theta}$. After obtaining the approximation $u_t^{\theta}$, we solve the corresponding <strong><em>ODE</em></strong> to get the trajectory $\psi_t^{\theta}(X_0)$.</p> <p>We want the sample distribution to exactly match $p_{data}$ when the model evolves to the endpoint $t=1$:</p> \[X_1=\psi_1^{\theta}(X_0)\sim p_{data}\] <p>Generally, we train $\theta$ through <strong><em>Flow Matching</em></strong> to make the evolved distribution consistent with the data distribution, i.e., to have the endpoint $X_1$ of the <strong><em>trajectory</em></strong> follow the $p_{data}$ distribution.</p> <p>After learning the vector field $u_t^{\theta}$, we need to numerically solve the $ODE$ (using first-order Euler method) to obtain $X_t$:</p> \[X_{t+h}=X_t+hu_t^{\theta}(X_t)\] <p>Below, we will focus on introducing the <strong><em>Flow Matching</em></strong> technique.</p> <h2 id="flow-matching">Flow Matching</h2> <p>An intuitive method for training <strong>Continuous Normalizing Flows</strong> is to obtain the distribution of $x_1$ by solving the <strong>ODE</strong> given initial condition $x_0$, and then constrain it to match the true data distribution using a divergence minimization measure (such as KL divergence). However, since intermediate trajectories are numerous and unknown, inferring $x_1$ (through sampling or computing likelihood) requires repeated <strong>ODE</strong> simulations, resulting in enormous computational cost. To address this, the paper proposes a new method called <strong>Flow Matching (FM)</strong>.</p> <p><strong>Flow Matching</strong> is a technique suitable for training <strong>Continuous Normalizing Flows</strong> that is <strong>Simulation-Free</strong>, meaning it does not require ODE inference of the target data distribution. <strong>Its core idea is to ensure that the dynamic characteristics between the model-predicted vector field and the vector field describing the actual motion of data points remain consistent, thereby ensuring that the final probability distribution obtained through CNFs transformation matches the expected target distribution.</strong></p> <p>Specifically, given a target probability density path $p_t(x)$ and its corresponding vector field $u_t(x)$, where the probability density path $p_t(x)$ is generated by this vector field $u_t(x)$, and $v_t(x)$ is the vector field to be learned, the <strong>Flow Matching</strong> optimization objective can be defined as:</p> \[\color{red} \mathcal L_{FM}(\theta)=\mathbb E_{t\sim U[0,1],x\sim p_t(x)}\|v_t(x)-u_t(x)\|^2\] <p>The core of the <strong>Flow Matching</strong> objective is to minimize this loss function so that its predicted vector field $v_t(x)$ is as close as possible to the actual vector field $u_t(x)$, thereby accurately generating the target probability density path $p_t(x)$.</p> <h3 id="continuity-equation">Continuity Equation</h3> <p><strong>In physics, the Continuity Equation is a partial differential equation that describes the transport behavior of conserved quantities</strong>. Under appropriate conditions, mass, energy, momentum, charge, etc., are all conserved quantities, so many transport behaviors can be described using the continuity equation.</p> \[\frac{\partial \rho}{\partial t}+\nabla \cdot (\rho v)=0\] <p>where $\rho$ is the fluid density, $v$ is the fluid velocity vector, $\frac{\partial \rho}{\partial t}$ is the rate of change of fluid density over time, and $\nabla \cdot (\rho v)$ is the divergence of the mass flux density. The meaning of this equation is: the rate of mass change within any closed volume in the fluid equals the difference between the mass flux flowing in and out of that space.</p> <p>By analogy to probability distributions, this equation can be written as:</p> \[\color{red}\frac{\partial p_t(x)}{\partial t}+\nabla \cdot (p_t(x)v_t(x))=0\] <p>In the above equation, $p_t(x)$ is the probability density function at time $t$, and $v_t(x)$ is the vector field associated with $p_t(x)$. This equation is a necessary and sufficient condition for the vector field $v_t(x)$ to generate the probability density path $p_t(x)$, and will be used as a constraint in subsequent derivations.</p> <p>For conditional probability, the above equation becomes</p> \[\frac{\partial p_t(x|x_1)}{\partial t}+\nabla \cdot (p_t(x|x_1)v_t(x|x_1))=0\] <h3 id="conditional-and-marginal-probability-paths-and-vector-fields">Conditional and Marginal Probability Paths and Vector Fields</h3> <p>Since we need to predetermine appropriate $p_t(x)$ and $u_t(x)$ during training, this is obviously difficult. However, we can start from the true distribution $q(x_1)$ and transform the true distribution into other simple distributions through invertible transformations. In this process, we can explicitly write out the <strong>conditional probability path</strong> $p_t(x|x_1)$, and according to the <strong><em>Continuity Equation</em></strong>, we can derive the conditional vector field. <strong><em>By weighting the conditional vector field and conditional probability path (density) using Bayes’ formula, we can recover the marginal probability path and marginal vector field, namely</em></strong> $p_t(x)$ <strong><em>and</em></strong> $u_t(x)$.</p> <p>Since the marginal density is the integral of the conditional density:</p> \[p_t(x)=\int p_t(x|x_1)q(x_1)dx_1\] <p>Thus, its partial derivative with respect to $t$ is:</p> \[\frac{\partial p_t(x)}{\partial t}=\int \frac{\partial p_t(x|x_1)}{\partial t}q(x_1)dx_1=-\int \nabla \cdot (p_t(x|x_1)u_t(x|x_1))q(x_1)dx_1\] <p>According to the continuity equation, if we want a vector field $u_t(x)$ to correspond to the probability path $p_t(x)$, then we must have:</p> \[-\nabla \cdot (p_t(x)u_t(x))=-\int \nabla \cdot (p_t(x|x_1)u_t(x|x_1))q(x_1)dx_1\] <p>We can solve to get</p> \[\color{red}u_t(x)=\int u_t(x|x_1)\frac{p_t(x|x_1)}{p_t(x)}q(x_1)dx_1\] <p>This means that if the marginal vector field $u_t(x)$ is given by the above equation, then it will correspondingly generate the marginal probability path $p_t(x)$.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-5-Note-FM/figure4-480.webp 480w,/assets/img/posts/2025-11-5-Note-FM/figure4-800.webp 800w,/assets/img/posts/2025-11-5-Note-FM/figure4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-5-Note-FM/figure4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>As shown in the figure above, computing the marginal vector field essentially performs a weighted average over all possible conditional vectors.</p> <h3 id="conditional-flow-matching">Conditional Flow Matching</h3> <p>We find that even though we have the formula for computing $u_t(x)$, the above marginal integral is still intractable, so directly optimizing the <strong><em>Flow Matching</em></strong> objective function is infeasible.</p> <p>The paper proposes the <strong>Conditional Flow Matching</strong> method. <strong>As long as</strong> $u_t(x|x_1)$ <strong>and</strong> $u_t(x)$ <strong>satisfy the above weighted marginal integral condition</strong>, the <strong>Conditional Flow Matching</strong> optimization objective has the same optimal solution as the original <strong>Flow Matching</strong> objective function. The <strong>Conditional Flow Matching</strong> optimization objective is:</p> \[\color{red} \mathcal L_{CFM}(\theta)=\mathbb E_{t\sim U[0,1],x_1\sim q(x_1),x\sim p_t(x|x_1)}\|v_t(x)-u_t(x|x_1)\|^2\] <p>The paper proves through <strong>Theorem1</strong> that the <strong>Conditional Flow Matching</strong> optimization objective and the original <strong>Flow Matching</strong> objective function have the <strong>same gradient</strong>, which means they have the <strong>same optimal solution</strong>.</p> <blockquote> <p><strong><em>Theorem1</em></strong> Assume that for all $x\in\mathbb R^d$ and $t\in [0,1]$, we have $p_t(x)&gt;0$. Then $\mathcal L_{CFM}$ and $\mathcal L_{FM}$ differ by a constant independent of $\theta$, i.e.,</p> \[\nabla _{\theta}\mathcal L_{FM}(\theta)=\nabla _{\theta}\mathcal L_{CFM}(\theta)\] <p><strong><em>Proof</em></strong></p> <p>To ensure the existence of integrals and to facilitate exchanging the order of integration (using Fubini’s theorem), we assume that $q(x)$ and $p_t(x_1)$ decay to 0 sufficiently fast as $|x|\to\infty$, and that $u_t$, $v_t$, $\nabla v_t$ are all bounded.</p> <p>First, we expand the squared norm:</p> \[\begin{align*} \|v_t(x) - u_t(x)\|^2 &amp;= \|v_t(x)\|^2 - 2 \langle v_t(x), u_t(x) \rangle + \|u_t(x)\|^2 \\ \|v_t(x) - u_t(x \mid x_1)\|^2 &amp;= \|v_t(x)\|^2 - 2 \langle v_t(x), u_t(x \mid x_1) \rangle + \|u_t(x \mid x_1)\|^2 \end{align*}\] <p>Next, note that $u_t$ is independent of $\theta$, and we have:</p> \[\begin{align*} \mathbb{E}_{p_t(x)} \|v_t(x)\|^2 &amp;= \int \|v_t(x)\|^2 p_t(x) dx \\ &amp;= \iint \|v_t(x)\|^2 p_t(x \mid x_1) q(x_1) dx_1 dx \\ &amp;= \mathbb{E}_{q(x_1), p_t(x \mid x_1)} \|v_t(x)\|^2 \end{align*}\] <p>Next, we compute:</p> \[\begin{align*} \mathbb{E}_{p_t(x)} \langle v_t(x), u_t(x) \rangle &amp;= \int \left\langle v_t(x), \int u_t(x \mid x_1) \frac{p_t(x \mid x_1) q(x_1)}{p_t(x)} dx_1 \right\rangle p_t(x) dx \\ &amp;= \int \left\langle v_t(x), \int u_t(x \mid x_1) p_t(x \mid x_1) q(x_1) dx_1 \right\rangle dx \\ &amp;= \iint \langle v_t(x), u_t(x \mid x_1) \rangle p_t(x \mid x_1) q(x_1) dx dx_1 \\ &amp;= \mathbb{E}_{q(x_1), p_t(x \mid x_1)} \langle v_t(x), u_t(x \mid x_1) \rangle \end{align*}\] <p>Meanwhile, we note that the third term in the squared norm expansion is a constant independent of $\theta$, thus proving the theorem.</p> </blockquote> <p>Based on the above discussion, the core of constructing a trainable flow model becomes how to design appropriate conditional probability paths and conditional vector fields. Generally speaking, conditional probability paths are easier to construct, while conditional vector fields are more challenging. According to the <strong><em>Continuity Equation</em></strong>, we know</p> \[\frac{\partial p_t(x|x_1)}{\partial t}+\nabla \cdot (p_t(x|x_1)v_t(x|x_1))=0\] <p>This equation allows us to explicitly compute a closed-form $v_t(x|x_1)$ when $p_t(x|x_1)$ is a Gaussian family or a simple function.</p> <h3 id="calculate-conditional-probability-paths-and-conditional-vector-fields">Calculate Conditional Probability Paths and Conditional Vector Fields</h3> <p><strong>Conditional Flow Matching</strong> can choose arbitrary conditional probability paths as long as they satisfy boundary conditions. Here, for simplicity (to obtain a closed-form conditional vector field), we analyze how to construct $p_t(x|x_1)$ and $u_t(x|x_1)$ for general <strong>Gaussian conditional probability paths</strong>.</p> <p>Assume the conditional probability path is a <strong>Gaussian probability path</strong>:</p> \[p_t(x|x_1)=\mathcal N(x|\mu_t(x_1),\sigma_T(x_1)^2I)\] <p>We impose the following constraints on this conditional probability path:</p> <p>At the beginning of time ($t=0$), we satisfy $\mu_0(x_1) = 0, \sigma_0(x_1) = 1$, ensuring that all conditional probability paths converge to the same standard Gaussian noise distribution, i.e., $p(x) = \mathcal{N}(x \mid 0, I)$.</p> <p>At the end of time ($t=1$), we satisfy $\mu_1(x_1) = x_1, \sigma_1(x_1) = \sigma_{\min}$, where $\sigma_{\min}$ should be set sufficiently small to ensure that $p(x \mid x_1)$ is a Gaussian distribution with mean $x_1$ and small variance, so that the conditional probability path converges near $x_1$.</p> <p>This setting defines a deterministic transformation process, starting from a standard Gaussian distribution at $t=0$ and gradually transforming to the target distribution at $t=1$.</p> <p>For a probability path, <strong>there exist infinitely many vector fields that can generate it</strong>, for example, by adding a divergence-free component to the <strong>Continuity Equation</strong>, but this leads to unnecessary computational cost. Here we can use the simplest vector field, <strong>which corresponds to the standard transformation of a Gaussian distribution, with the corresponding data point Flow Map being</strong>:</p> \[x_t=\psi_t(x)=\sigma_t(x_1)x+\mu_t(x_1)\] <p>where $x\sim\mathcal N(0,1)$. $\psi_t(x)$ is an affine transformation that maps $x$ to a normal random variable with mean $\mu_t(x_1)$ and standard deviation $\sigma_t(x_1)$. That is, according to Equation 4, $\psi_t$ pushes the noise distribution $p_0(x|x_1) = p(x)$ to $p_t(x|x_1)$, i.e.,</p> \[\begin{equation} [\psi_t]_∗ p(x) = p_t(x|x_1). \end{equation}\] <p>The flow further defines a vector field that generates the conditional probability path:</p> \[\begin{equation} \frac{d}{dt} \psi_t(x) = u_t(\psi_t(x) \mid x_1). \end{equation}\] <p>Reparametrizing $p_t(x|x_1)$ in terms of $x_0$ and substituting into Equation (13), we obtain the CFM loss function as follows:</p> \[\begin{equation} \mathcal{L}_{\text{CFM}}(\theta) = \mathbb{E}_{t, q(x_1), p(x_0)} \left\| v_t(\psi_t(x_0)) - \frac{d}{dt} \psi_t(x_0) \right\|^2. \end{equation}\] <p>Since $\psi_t$ is a simple (invertible) affine mapping, we can utilize Equation (13) to obtain a closed-form solution for $u_t$. Let $f’$ denote the derivative with respect to time $t$, i.e., $f’ = \frac{d}{dt} f$, where $f$ is a time-dependent function.</p> <blockquote> <p><strong><em>Theorem2</em></strong> Let $p_t(x|x_1)$ be the Gaussian probability path as defined in Equation 10, and $\psi_t$ be its corresponding flow map as described in Equation 11. Then the vector field that uniquely defines $\psi_t$ has the following form:</p> \[u_t(x|x_1) = \frac{\sigma'_t(x_1)}{\sigma_t(x_1)} \left( x - \mu_t(x_1) \right) + \mu'_t(x_1)\] <p>Therefore, $u_t(x|x_1)$ generates the Gaussian path $p_t(x|x_1)$</p> <p><strong><em>Proof:</em></strong></p> <p>For notational brevity, let $w_t(x) = u_t(x|x_1)$. Now consider Equation 1:</p> \[\frac{d}{dt}\psi_t(x) = w_t(\psi_t(x)).\] <p>Since $\psi_t$ is invertible (because $\sigma_t(x_1) &gt; 0$), we set $x = \psi_t^{-1}(y)$ and obtain</p> \[\psi_t'(\psi_t^{-1}(y)) = w_t(y)\] <p>Here we use prime notation to denote derivatives, emphasizing that $\psi_t’$ is evaluated at $\psi_t^{-1}(y)$.</p> <p>Now, inverting $\psi_t(x)$ yields</p> \[\psi_t^{-1}(y) = \frac{y - \mu_t(x_1)}{\sigma_t(x_1)}.\] <p>Taking the derivative of $\psi_t$ with respect to $t$ yields</p> \[\psi_t'(x) = \sigma_t'(x_1)x + \mu_t'(x_1).\] <p>Substituting these last two equations into the second line, we obtain</p> \[w_t(y) = \frac{\sigma_t'(x_1)}{\sigma_t(x_1)}(y - \mu_t(x_1)) + \mu_t'(x_1).\] </blockquote> <h2 id="special-instances-of-gaussian-conditional-probability-paths">Special Instances of Gaussian Conditional Probability Paths</h2> <h3 id="diffusion-conditional-vfs">Diffusion conditional VFs</h3> <p><strong>Variance Exploding (VE) and Variance Preserving (VP)</strong> in diffusion models are two different types of diffusion processes used in generative models to simulate two different data distribution change processes.</p> <h4 id="variance-exploding-ve">Variance Exploding (VE)</h4> <p>The VE diffusion model is a diffusion process that increases data variance during the generation process. In this model, as time progresses, data samples gradually become more noisy, with variance continuously increasing until reaching a stable state. A characteristic of the VE process is that it allows the model to explore a wider latent space when generating data, which helps generate diverse samples.</p> <p>The conditional probability path for VE is:</p> \[p_t(x | x_1) = \mathcal{N}(x | x_1, \sigma_{1-t}^2 I)\] <p>where $\sigma_t$ is an increasing function, $\sigma_0 = 0, \sigma_1 \gg 1$, corresponding to mean and standard deviation</p> \[\mu_t(x_1) = x_1, \quad \sigma_t(x_1) = \sigma_{1-t}\] <p>According to Theorem 3, the conditional vector field can be computed as:</p> \[u_t(x | x_1) = - \frac{\sigma'_{1-t}}{\sigma_{1-t}}(x - x_1)\] <h4 id="variance-preserving-vp">Variance Preserving (VP)</h4> <p>The VP diffusion model is a diffusion process that keeps data variance constant during the generation process. In this model, the variance of data samples remains constant throughout the generation process, meaning that while the model introduces noise, it also reduces noise in some way to maintain the overall variance of the data. VP models are typically used in application scenarios that require maintaining data distribution stability, such as maintaining image clarity and structural features in image generation.</p> <p>The conditional probability path for VP is:</p> \[p_t(x | x_1) = \mathcal{N}\left(x \mid \alpha_{1-t}x_1, (1 - \alpha_{1-t}^2)I\right) \text{, where } \alpha_t = e^{-\frac{1}{2}T(t)}, T(t) = \int_0^t \beta(s)ds\] <p>where $\alpha, \beta$ are noise schedule functions, corresponding to mean and standard deviation</p> \[\mu_t(x_1) = \alpha_{1-t}x_1, \quad \sigma_t(x_1) = \sqrt{1 - \alpha_{1-t}^2} \,。\] <p>According to Theorem 3, the conditional vector field can be computed as:</p> \[\begin{align*} u_t(x | x_1) &amp;= \frac{\alpha'_{1-t}}{1-\alpha_{1-t}^2}(\alpha_{1-t}x - x_1) \\ &amp;= -\frac{T'(1-t)}{2}\left[ \frac{e^{-T(1-t)}x - e^{-\frac{1}{2}T(1-t)}x_1}{1-e^{-T(1-t)}} \right] \end{align*}\] <h3 id="optimal-transport-conditional-vfs">Optimal Transport conditional VFs</h3> <p>Optimal Transport (OT) chooses to define the mean and standard deviation of the conditional probability path as simple linear functions. As time $t: 0 \to 1$, corresponding to the probability density path from $p(x) = \mathcal{N}(x | 0, I)$ to $p_1(x | x_1)$, the mean and standard deviation are defined as:</p> \[\mu_t(x_1) = tx_1, \quad \text{and} \quad \sigma_t(x_1) = 1 - (1 - \sigma_{\min})t\] <p>Then the corresponding Flow Map is:</p> \[\psi_t(x) = (1 - (1 - \sigma_{\min})t)x + tx_1\] <p>According to Theorem 3, the closed-form solution of the conditional vector field can be computed as:</p> \[u_t(x | x_1) = \frac{x_1 - (1 - \sigma_{\min})x}{1 - (1 - \sigma_{\min})t}\] <p><strong><em>Optimal transport paths are straight lines, whereas diffusion paths are curves, thus achieving faster training and generation speeds, as well as better performance.</em></strong></p>]]></content><author><name>Runze Tian</name></author><category term="Notes"/><category term="Gen-Model"/><category term="flow-matching"/><category term="ImageGen"/><summary type="html"><![CDATA[This post explores Flow-based Models, Continuous Normalizing Flows (CNFs), and Flow Matching (FM). We discuss Normalizing Flows, derive the conditional flow matching objective, and examine special instances including diffusion models and optimal transport.]]></summary></entry><entry><title type="html">The Unification of DDPM and Score-based Models</title><link href="https://gua927.github.io/blog/2025/Note-Diffusion-DDPM-and-NCSN/" rel="alternate" type="text/html" title="The Unification of DDPM and Score-based Models"/><published>2025-11-03T14:17:00+00:00</published><updated>2025-11-03T14:17:00+00:00</updated><id>https://gua927.github.io/blog/2025/Note-Diffusion-DDPM-and-NCSN</id><content type="html" xml:base="https://gua927.github.io/blog/2025/Note-Diffusion-DDPM-and-NCSN/"><![CDATA[<h2 id="ddpm-from-a-score-perspective">DDPM from a Score Perspective</h2> <p>In <strong><em>DDPM</em></strong> (<a class="citation" href="#ho2020denoisingdiffusionprobabilisticmodels">(Ho et al., 2020)</a>), we know that</p> \[x_t\sim q(x_t|x_0) = N(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I) \tag{1}\] <p>According to <strong><em>Tweedie’s Formula</em></strong>, we can obtain:</p> \[\sqrt{\bar{\alpha}_t} \boldsymbol{x}_0 = \boldsymbol{x}_t + (1 - \bar{\alpha}_t) \nabla_{x_t} \log p(\boldsymbol{x}_t) \tag{2}\] <blockquote> <p><strong><em>Tweedie’s Formula:</em></strong></p> <p>For a Gaussian variable $z\sim \mathcal N(z;\mu_z,\Sigma_z)$, we have</p> \[\mu_z=z+\Sigma_z\nabla_z\log p(z)\] </blockquote> <p>Meanwhile, from (1) we know</p> \[x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t\] <p>Substituting into (2), we obtain</p> \[\nabla_{x_t}\log p(x_t)=-\frac{\epsilon_t}{\sqrt{1-\bar{\alpha}_t}}\] <p>Thus</p> \[\begin{align*} \boldsymbol{\mu}_q &amp;= \frac{1}{\sqrt{\alpha_t}} \boldsymbol{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t} \sqrt{\alpha_t}} \boldsymbol{\varepsilon}_t\\ &amp;=\frac{1}{\sqrt{\alpha_t}} \boldsymbol{x}_t + \frac{1 - \alpha_t}{\sqrt{\alpha_t}} \color{red}\nabla_{x_t} \log p(\boldsymbol{x}_t) \end{align*}\] <p>Similarly, we model the reverse process as</p> \[\begin{align*} \boldsymbol{\mu}_{\theta} &amp;= \frac{1}{\sqrt{\alpha_t}} \boldsymbol{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t} \sqrt{\alpha_t}} \boldsymbol{\varepsilon}_{\theta}(x_t,t)\\ &amp;=\frac{1}{\sqrt{\alpha_t}} \boldsymbol{x}_t + \frac{1 - \alpha_t}{\sqrt{\alpha_t}} \color{red}s_{\theta}(x_t,t) \end{align*}\] <p>Therefore, we transform the estimation of $\epsilon_t$ and $\epsilon_{\theta}$ in <strong><em>DDPM</em></strong> into the estimation of $\nabla\log p(x)$, which gives</p> \[\begin{align*} &amp;\arg\min_{\theta} D_{\text{KL}} \left( q(\boldsymbol{x}_{t-1} \vert \boldsymbol{x}_t, \boldsymbol{x}_0) \parallel p_{\theta}(\boldsymbol{x}_{t-1} \vert \boldsymbol{x}_t) \right) \\ =&amp; \arg\min_{\theta} \frac{1}{2\sigma_q^2(t)} \left[ \lVert \boldsymbol{\mu}_{\theta} - \boldsymbol{\mu}_q \rVert_2^2 \right] \\ =&amp; \arg\min_{\theta} \frac{1}{2\sigma_q^2(t)} \left[ \left\lVert \frac{1 - \alpha_t}{\sqrt{\alpha_t}} s_{\theta}(\boldsymbol{x}_t, t) - \frac{1 - \alpha_t}{\sqrt{\alpha_t}} \nabla \log p(\boldsymbol{x}_t) \right\rVert_2^2 \right] \\ =&amp; \arg\min_{\theta} \frac{1}{2\sigma_q^2(t)} \frac{(1 - \alpha_t)^2}{\alpha_t} \left[ \color{red}\lVert s_{\theta}(\boldsymbol{x}_t, t) - \nabla \log p(\boldsymbol{x}_t) \rVert_2^2 \color{black}\right] \end{align*}\] <p>Hence, we find that the optimization objective of DDPM is actually consistent with <strong><em>Score-Based Models</em></strong>, both estimating the <strong><em>score function</em></strong>.</p> <p>We further compare the optimization objective of DDPM:</p> \[L_t = \mathbb{E} \left[ \frac{(1 - \alpha_t)^2}{2\alpha_t (1 - \bar{\alpha}_t) \sigma^2} \color{red}\left\| \boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta \left( x_t, t \right) \right\|_2^2 \color{black}\right]\] <p>We note that when $L_t$ reaches its optimum, we have</p> \[\epsilon_{\theta}(x_t,t)=\mathbb E\big[\epsilon_t|x_t,t\big]=\mathbb E\big[\epsilon_t|x_0,t\big]\] <p>This indicates that the model actually learns the mean of the noise given data $x_0$. In other words, the conditional expectation learned by our network already contains information about the true sample $x_0$, which is what enables us to obtain the distribution of true data by learning the noise.</p> <p>Meanwhile, we find that under optimal conditions, $L_t$ cannot reach 0, meaning that our optimization objective does not achieve maximum likelihood between the predicted distribution and the true distribution (otherwise the loss should reduce to 0). Combined with <strong><em>Score-Based Models</em></strong>, we know this is because we are actually predicting the <strong><em>score</em></strong> of the data distribution, and there is still a certain gap between the score distribution and the data distribution.</p> <hr/> <h2 id="sde-model">SDE Model</h2> <p>What happens if we extend the finite steps $T$ to infinite steps? Experimental validation shows that larger $T$ can yield more accurate likelihood estimates and better quality results. Thus, continuous-time perturbation of data can be modeled as a stochastic differential equation (SDE).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-03-Note-Diffusion/figure1-480.webp 480w,/assets/img/posts/2025-11-03-Note-Diffusion/figure1-800.webp 800w,/assets/img/posts/2025-11-03-Note-Diffusion/figure1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-03-Note-Diffusion/figure1.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="definition">Definition</h3> <p>There are many forms of SDEs. One form given by Dr. Yang Song in his paper <a class="citation" href="#song2021scorebasedgenerativemodelingstochastic">(Song et al., 2021)</a> (which can be considered a Diffusion-Type SDE, requiring coefficients to depend only on time <code class="language-plaintext highlighter-rouge">t</code> and current value <code class="language-plaintext highlighter-rouge">x</code>) is:</p> \[\mathrm{d}\boldsymbol{x} = f(\boldsymbol{x}, t)\mathrm{d}t + g(t)\mathrm{d}\boldsymbol{w}\] <p>where $f(\cdot)$ is called the drift coefficient, $g(t)$ is called the diffusion coefficient, $\boldsymbol{w}$ is a standard Brownian motion, and $\mathrm{d}\boldsymbol{w}$ can be viewed as white noise. The solution to this stochastic differential equation is a set of continuous random variables $\lbrace\boldsymbol x(t)\rbrace_{t\in [0,T]}$, where $t$ represents the continuous version of the discrete form $(1, 2, \ldots, T)$.</p> <p>We use $p_t(\boldsymbol{x})$ to denote the probability density function of $\boldsymbol{x}(t)$, which corresponds to the previous $p_{\sigma_t}(\boldsymbol{x}_t)$. Here $p_0(\boldsymbol{x}) = p(\boldsymbol{x})$ is the original data distribution, and $p_T(\boldsymbol{x}) = \mathcal{N}(0, \mathbf{I})$ is the white noise obtained after noise perturbation.</p> <blockquote> <p><strong><em>Brownian Motion</em></strong></p> <p>If a stochastic process $\lbrace X(t), t \geq 0\rbrace$ satisfies:</p> <ul> <li>$X(t)$ is an independent increment process;</li> <li>$\forall s, t &gt; 0, X(s + t) - X(s) \sim N(0, c^2 t)$</li> </ul> <p>then the stochastic process $\lbrace X(t), t \geq 0\rbrace$ is called <strong>Brownian motion</strong> (denoted as $B(t)$) or <strong>Wiener process</strong> (denoted as $W(t)$). In this text, we will subsequently denote it as $W(t)$. If $c = 1$, it is called <strong>standard Brownian motion</strong>, satisfying $W(t) \sim N(0, t)$.</p> </blockquote> <h3 id="forward-sde">Forward SDE</h3> <p>We can directly discretize the equation</p> \[\mathrm{d}\boldsymbol{x} = f(\boldsymbol{x}, t)\mathrm{d}t + g(t)\mathrm{d}\boldsymbol{w}\] <p>where</p> \[dx\to x_{t+\Delta t}-x_t\\ dt\to \Delta t\\ dw\to w(t+\Delta t)-w(t)\sim\mathcal N(0,\Delta t)=\sqrt{\Delta t}\epsilon\] <p>Thus, the discrete form of the SDE is represented as:</p> \[\color{red} x_{t+\Delta t}-x_t=f(x,t)\Delta t+g(t)\sqrt{\Delta t}\epsilon\] <p>where $\epsilon\sim\mathcal N(0,1)$.</p> <h4 id="ve-sde">VE-SDE</h4> <p>For NCSN, the forward process (adding noise) is shown as follows:</p> \[x_t=x_0+\sigma_t\epsilon\\ x_{t+\Delta t}=x_t+\underbrace{\sqrt{\sigma_{t+\Delta t}^2-\sigma_t^2}}_{\color{red}\sqrt{\frac{\sigma_{t+\Delta t}^2-\sigma_t^2}{\Delta t}}\sqrt{\Delta t}}\epsilon\] <p>Therefore, in the corresponding SDE representation</p> \[f(x_t,t)=0\\ g(t)=\lim\limits_{\Delta\to 0}\sqrt{\frac{\sigma_{t+\Delta t}^2-\sigma_t^2}{\Delta t}}=\sqrt{2\sigma_t\dot\sigma_t}\] <p>The corresponding continuous <strong>SDE</strong> for the <strong>VE</strong> process is:</p> \[\color{blue}dx=\sqrt{2\sigma_t\dot\sigma_t}dW\] <h4 id="vp-sde">VP-SDE</h4> <p>For DDPM, its forward process is represented as follows:</p> \[x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon\\ x_{t+1}=\sqrt{1-\beta_{t+1}}x_t+\sqrt{\beta_{t+1}}\epsilon\] <p>We continualize the discrete time $1,2,\cdots,t,\cdots T$ to $[0,1]$, i.e., let</p> \[t\to\frac{t}{T}=t'\\ 1\to\frac{1}{T}=\Delta t\] <p>We can also let $\beta_{t’}=T\beta_t$, thus</p> \[\begin{align*} x_{t'+\Delta t}&amp;=x_{t+1}=\sqrt{1-\beta_{t+1}}x_t+\sqrt{\beta_{t+1}}\epsilon\\ &amp;=\sqrt{1-\beta_{t'+\Delta t}\Delta t}\cdot x_{t'}+\sqrt{\beta_{t'+\Delta t}\Delta t}\cdot \epsilon\\ &amp;=\big(1-\frac{1}{2}\beta_{t'}\Delta t\big)x_{t'}+\sqrt{\beta_{t'}}\sqrt{\Delta t}\epsilon \end{align*}\] <p>Therefore, in the corresponding SDE representation, we have</p> \[f(x_t,t)=-\frac{1}{2}\beta_{t'}x_t\\ g(t)=\sqrt{\beta_{t'}}\] <p>The corresponding continuous <strong>SDE</strong> for the <strong>VP</strong> process is:</p> \[\color{blue}dx=-\frac{1}{2}\beta_{t'}x_tdt+\sqrt{\beta_{t'}}dW\] <p>We expect that when $t\to T$, the image becomes pure noise, then $\sigma_t\to\infty$, but $\bar{\alpha}_t\to 0$ is sufficient. This requires that in <strong>NCSN</strong>, the variance of noise gradually expands, while in <strong>DDPM</strong>, the noise variance remains between $(0,1)$. Therefore, they are respectively called <strong>VE-SDE</strong> and <strong>VP-SDE</strong>.</p> <h3 id="reverse-sde">Reverse SDE</h3> <p>Using the discrete forward <strong>SDE</strong>, we can derive its reverse process. From the forward <strong>SDE</strong>:</p> \[\color{red} x_{t+\Delta t}-x_t=f(x,t)\Delta t+g(t)\sqrt{\Delta t}\epsilon\] <p>we have the conditional probability:</p> \[x_{t+\Delta t}|x_t\sim \mathcal{N}(x_t+f(x_t,t)\Delta t, g^2(t)\Delta tI)\] <p>Considering the reverse process from $x_{t+\Delta t}$ to $x_t$, we have the conditional probability:</p> \[\begin{align*} p(x_t|x_{t+\Delta t})&amp;=\frac{p(x_{t+\Delta t}|x_t)p(x_t)}{p(x_{t+\Delta t})}\\ &amp;=p(x_{t+\Delta t}|x_t)\exp(\log p(x_t)-\log p(x_{t+\Delta t}))\\ &amp;\approx p(x_{t+\Delta t}|x_t)\exp\{\color{red} -(x_{t+\Delta t}-x_t)\nabla_{x_t}\log p(x_t)-\Delta t\frac{\partial}{\partial t}\log p(x_t) \color{black}\}\\ &amp;\propto \exp\{ -\frac{\|x_{t+\Delta t}-x_t-f(x_t,t)\Delta t\|_2^2}{2g^2(t)\Delta t} - (x_{t+\Delta t}-x_t)\nabla_{x_t}\log p(x_t)-\Delta t\frac{\partial}{\partial t}\log p(x_t) \}\\ &amp;=\exp\bigg\{ -\frac{1}{2g^2(t)\Delta t}\|(x_{t+\Delta t}-x_t)-\big[f(x_t,t)-g^2(t)\nabla_{x_t}\log p(x_t) \big]\Delta t\|_2^2 - \Delta t\frac{\partial}{\partial t}\log p(x_t)-\frac{f^2(x_t,t)\Delta t}{2g^2(t)}+\frac{\|f(x_t,t)-g^2(t)\nabla_{x_t}\log p(x_t) \|_2^2\Delta t}{2g^2(t)} \bigg\}\\ &amp;\stackrel{\Delta t \to 0}{=} \exp\bigg\{ -\frac{1}{2g^2(t)\Delta t}\| (x_{t+\Delta t}-x_t)-\big[f(x_t,t)-g^2(t)\nabla_{x_t}\log p(x_t) \big]\Delta t \|_2^2 \bigg\} \end{align*}\] <p>Therefore, $x_t|x_{t+\Delta t}$ follows a Gaussian distribution with mean and variance as follows:</p> \[\mu=x_{t+\Delta t}-\big[f(x_t,t)-g^2(t)\nabla_{x_t}\log p(x_t) \big]\Delta t\\ \sigma^2=g^2(t)\Delta t\] <p>Thus, we can obtain both the discrete and continuous forms of the reverse SDE process:</p> \[x_{t+\Delta t}-x_t=\big[f(x_t+\Delta t,t+\Delta t)-g^2(t+\Delta t)\nabla_{x_t+\Delta t}\log p(x_{t+\Delta t}) \big]\Delta t+g(t+\Delta t)\sqrt{\Delta t}\epsilon\] \[\color{blue}dx=\big[f(x_t,t)-g^2(t)\color{red}\nabla_{x_t}\log p(x_t)\color{blue} \big]dt+g(t)dW\] <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-03-Note-Diffusion/figure2-480.webp 480w,/assets/img/posts/2025-11-03-Note-Diffusion/figure2-800.webp 800w,/assets/img/posts/2025-11-03-Note-Diffusion/figure2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-03-Note-Diffusion/figure2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Therefore, after we have learned the <strong><em>score function</em></strong>, the reverse process becomes completely solvable. During generation, we start by sampling $x_T \sim \mathcal{N}(0, 1)$, and gradually obtain $x_0$ using the discrete process above. This discretization method for stochastic differential equations is also called the <strong>Euler–Maruyama method</strong>.</p> <p>For NCSN, its forward VE process continuous SDE is:</p> \[\color{blue}dx=\sqrt{2\sigma_t\dot\sigma_t}dW\] <p>Then its reverse process is:</p> \[dx=-2\sigma_t\dot\sigma_t\nabla_{x_t}\log p(x_t)dt+\sqrt{2\sigma_t\dot\sigma_t}dW\] <p>Written in discrete form, it becomes</p> \[x_t-x_{t-1}=-2\sigma_t\dot\sigma_t\nabla_{x_t}\log p(x_t)\Delta t+\sqrt{2\sigma_t\dot\sigma_t}\sqrt{\Delta t}\epsilon_t\] <p>In the case where $\sigma_t\dot\sigma_t=1$, if we set $\Delta t=\delta$ (this is done only for formal consistency, without real meaning), then we have</p> \[x_{t-1}=x_t+2\delta\nabla_{x_t}\log p(x_t)+\sqrt{2\delta}\epsilon\] <p>This also unifies with the <strong><em>Langevin Equation</em></strong> mentioned earlier.</p> <h3 id="optimization-target">Optimization Target</h3> <p>Solving the reverse SDE requires us to know the terminal distribution $p_T(\boldsymbol{x})$ and the score function $\nabla_{\boldsymbol{x}} \log p_t(\boldsymbol{x})$. By design, the former is close to the prior distribution $\pi(\boldsymbol{x})$, which is fully tractable.</p> <p>To estimate $\nabla_{\boldsymbol{x}} \log p_t(\boldsymbol{x})$, we train a <strong>time-dependent score-based model</strong> $s_\theta(\boldsymbol{x}, t)$ such that $s_\theta(\boldsymbol{x}, t) \approx \nabla_{\boldsymbol{x}} \log p_t(\boldsymbol{x})$. This is similar to NCSN’s $s_\theta(\boldsymbol{x}, i)$, which after training satisfies $s_\theta(\boldsymbol{x}, i) \approx \nabla_{\boldsymbol{x}} \log p_{\sigma_i}(\boldsymbol{x})$.</p> <p>Our training objective for $s_\theta(\boldsymbol{x}, t)$ is a continuous weighted combination of Fisher divergences, given by (see <a class="citation" href="#song2019slicedscorematchingscalable">(Song et al., 2019)</a>; <a class="citation" href="#song2021scorebasedgenerativemodelingstochastic">(Song et al., 2021)</a>):</p> \[\mathbb{E}_{t \in \mathcal{U}(0,T)} \mathbb{E}_{p_t(\mathbf{x})} \left[ \lambda(t) \left\| \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) - \mathbf{s}_\theta(\mathbf{x}, t) \right\|_2^2 \right]\] <h4 id="relationship-with-likelihood">Relationship with Likelihood</h4> <p>When $\lambda(t)=g^2(t)$, under some regularity conditions, there exists an important connection between our weighted combination of Fisher divergences and the KL divergence from $p_0$ to $p_\theta$:</p> \[\begin{align*} \mathrm{KL}(p_0(\mathbf{x}) \| p_\theta(\mathbf{x})) &amp;\leq \frac{T}{2} \mathbb{E}_{t \in \mathcal{U}(0,T)} \mathbb{E}_{p_t(\mathbf{x})} \left[ \lambda(t) \| \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) - \mathbf{s}_\theta(\mathbf{x}, t) \|_2^2 \right] \\ &amp;+ \mathrm{KL}(p_T \| \pi) \end{align*}\] <p>Due to this special connection with KL divergence, and the equivalence between minimizing KL divergence and maximizing likelihood in model training, we call $\lambda(t)=g(t)^2$ the <strong>likelihood weighting function</strong>. Using this likelihood weighting function, we can train score-based generative models to achieve very high likelihoods.</p> <h3 id="pc-sampling">PC Sampling</h3> <p>Reviewing DDPM and NCSN from an algorithmic implementation perspective, DDPM is based on the Markov assumption, assuming that samples at different times follow conditional probability distributions. Therefore, DDPM uses Ancestral Sampling to solve the SDE equation, with the algorithm shown below:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-03-Note-Diffusion/figure3-480.webp 480w,/assets/img/posts/2025-11-03-Note-Diffusion/figure3-800.webp 800w,/assets/img/posts/2025-11-03-Note-Diffusion/figure3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-03-Note-Diffusion/figure3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>While NCSN relies on Langevin Dynamics for iterative optimization under the same noise distribution. For different noise magnitudes, there is no dependency relationship between the obtained samples. Its sampling method is shown as follows:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-03-Note-Diffusion/figure4-480.webp 480w,/assets/img/posts/2025-11-03-Note-Diffusion/figure4-800.webp 800w,/assets/img/posts/2025-11-03-Note-Diffusion/figure4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-03-Note-Diffusion/figure4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The former can be seen as solving the discrete form of the SDE equation, called the Predictor, while the latter can be seen as a further optimization process, called the Corrector. The author combines these two parts to present the Predictor-Corrector Sampling Method:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-03-Note-Diffusion/figure5-480.webp 480w,/assets/img/posts/2025-11-03-Note-Diffusion/figure5-800.webp 800w,/assets/img/posts/2025-11-03-Note-Diffusion/figure5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-03-Note-Diffusion/figure5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <hr/> <h2 id="probability-flow-ode">Probability Flow ODE</h2> <p>We can transform any <strong><em>SDE</em></strong> into an <strong><em>ODE</em></strong> without changing the marginal distributions $\lbrace p_t(x)\rbrace_{t\in[0,T]}$ of the stochastic differential equation. Therefore, by solving this <strong><em>ODE</em></strong>, we can sample from the same distribution as the <strong><em>Reverse SDE</em></strong>. The <strong><em>ODE</em></strong> corresponding to the <strong><em>SDE</em></strong> is called the <strong><em>Probability flow ODE</em></strong>, with the form:</p> \[\color{blue}dx=\big[f(x_t,t)-\frac{1}{2}g^2(t)\color{red}\nabla_{x_t}\log p(x_t)\color{blue} \big]dt\] <p>The figure below depicts trajectories of stochastic differential equations (SDEs) and probability flow ordinary differential equations (ODEs). It can be seen that ODE trajectories are significantly smoother than SDE trajectories, and they transform the same data distribution into the same prior distribution and vice versa, sharing the same set of marginal distributions $\lbrace p_t(\boldsymbol{x})\rbrace_{t\in[0,T]}$. In other words, trajectories obtained by solving the probability flow ODE have the same marginal distributions as SDE trajectories.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-11-03-Note-Diffusion/figure6-480.webp 480w,/assets/img/posts/2025-11-03-Note-Diffusion/figure6-800.webp 800w,/assets/img/posts/2025-11-03-Note-Diffusion/figure6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-11-03-Note-Diffusion/figure6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Using <strong><em>probability flow ODEs</em></strong> provides many benefits:</p> <ol> <li>Exact likelihood computation</li> <li>Manipulating latent representations</li> <li>Uniquely identifiable encoding</li> <li>Efficient sampling</li> </ol> <hr/> <h2 id="conditional-generation">Conditional Generation</h2> <p>According to Bayes’ theorem</p> \[p(x|y)=\frac{p(x)p(y|x)}{p(y)}\] <p>Taking the score with respect to $x$ on both sides gives</p> \[\nabla_x\log p(x|y)=\nabla_x\log p(x)+\nabla_x\log p(y|x)\] <p>Both latter terms are <strong><em>score functions</em></strong> that we can estimate. Therefore, we can generate $p(x|y)$ by solving the reverse SDE.</p> <h2 id="参考文献">参考文献</h2> <p><a class="citation" href="#ho2020denoisingdiffusionprobabilisticmodels">(Ho et al., 2020; Song et al., 2021; Song et al., 2019)</a></p> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="song2021scorebasedgenerativemodelingstochastic" class="col-sm-8"> <div class="title">Score-Based Generative Modeling through Stochastic Differential Equations</div> <div class="author"> Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Abhishek Kumar, Stefano Ermon, Ben Poole' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ho2020denoisingdiffusionprobabilisticmodels" class="col-sm-8"> <div class="title">Denoising Diffusion Probabilistic Models</div> <div class="author"> Jonathan Ho, Ajay Jain, and Pieter Abbeel </div> <div class="periodical"> 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="song2019slicedscorematchingscalable" class="col-sm-8"> <div class="title">Sliced Score Matching: A Scalable Approach to Density and Score Estimation</div> <div class="author"> Yang Song, Sahaj Garg, Jiaxin Shi, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Stefano Ermon' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2019 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol>]]></content><author><name>Runze Tian</name></author><category term="Notes"/><category term="Gen-Model"/><category term="diffusion-model"/><category term="score-matching"/><category term="ImageGen"/><summary type="html"><![CDATA[This post explores the unification of DDPM and Score-based Models in diffusion generative modeling. We show how x-prediction and score-prediction are fundamentally equivalent, and how both can be viewed through the lens of Stochastic Differential Equations (SDEs).]]></summary></entry></feed>